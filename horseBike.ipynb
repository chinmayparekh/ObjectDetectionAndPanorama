{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import svm\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './data'\n",
    "no_clusters = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDataset(): #Function to parse through the directory and append the required images and their labels\n",
    "    imgs = []\n",
    "    labels = []\n",
    "    label = -1\n",
    "    \n",
    "    directories = [f for f in os.listdir(data_path) if os.path.isdir(os.path.join(data_path, f))]\n",
    "    \n",
    "    for directory in directories:\n",
    "        label = label + 1\n",
    "        path = data_path+'/'+directory\n",
    "        files = [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]\n",
    "        \n",
    "        for file in files:\n",
    "            imgPath = path+'/'+file\n",
    "            imgs.append(imgPath)\n",
    "            labels.append(label)\n",
    "    \n",
    "    return (imgs,labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getImages(imgsPath):\n",
    "    imgs = []\n",
    "    for imgName in imgsPath:\n",
    "        img = cv2.imread(imgName)\n",
    "        imgs.append(img)\n",
    "    imgs = np.asarray(imgs,dtype=object)\n",
    "    return imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def getDescriptors(sift, img): #Function to detect the key points and their descriptors\n",
    "    kp, des = sift.detectAndCompute(img, None)\n",
    "    return des\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(imgs): # Function to extract all the descriptors of images\n",
    "    desc_list = []\n",
    "    count = 0\n",
    "    sift = cv2.SIFT_create()\n",
    "    for img in imgs:\n",
    "        desc = getDescriptors(sift,img)\n",
    "        if(desc is not None):\n",
    "            count = count+1\n",
    "            desc_list.append(desc)\n",
    "    return desc_list,count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vstackDescriptors(descriptor_list): #Reorganizing the descriptor list\n",
    "    descriptors = np.array(descriptor_list[0])\n",
    "    for descriptor in descriptor_list[1:]:\n",
    "        descriptors = np.vstack((descriptors, descriptor)) \n",
    "\n",
    "    return descriptors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clusterDescriptors(descriptors, no_clusters): #Applying kmeans on the descriptors\n",
    "    kmeans = KMeans(n_clusters = no_clusters).fit(descriptors)\n",
    "    return kmeans\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractFeatures(kmeans, descriptor_list, image_count, no_clusters): #Creating histograms which will later be used by the ML model as features\n",
    "    im_features = np.array([np.zeros(no_clusters) for i in range(image_count)])\n",
    "    for i in range(image_count):\n",
    "        for j in range(len(descriptor_list[i])):\n",
    "            feature = descriptor_list[i][j]\n",
    "            feature = feature.reshape(1, 128)\n",
    "            idx = kmeans.predict(feature)\n",
    "            im_features[i][idx] += 1\n",
    "\n",
    "    return im_features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeFeatures(scale, features): #Normalizing the features\n",
    "    return scale.transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = loadDataset()\n",
    "trainImgPaths,testImgPaths, trainLabels, testLabels = train_test_split(dataset[0], dataset[1], \n",
    "                                                train_size=0.8, random_state=42,shuffle = True,stratify = dataset[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(trainImgPaths):\n",
    "    trainImgs = getImages(trainImgPaths)\n",
    "    desc_list,count=extract(trainImgs)\n",
    "    descriptors = vstackDescriptors(desc_list)\n",
    "    kmeans = clusterDescriptors(descriptors, no_clusters=no_clusters)\n",
    "    im_features= extractFeatures(kmeans, desc_list, count, no_clusters=no_clusters)\n",
    "    scale = StandardScaler().fit(im_features)    \n",
    "    im_features = scale.transform(im_features)\n",
    "    LRG = linear_model.LogisticRegression().fit(im_features, trainLabels)\n",
    "    return kmeans,LRG,scale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans,LRG,scale= train(trainImgPaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(testImgPaths,kmeans,LRG,scale):\n",
    "    testImgs = getImages(testImgPaths)\n",
    "    desc_list,count=extract(testImgs)\n",
    "    descriptors = vstackDescriptors(desc_list)\n",
    "    test_features = extractFeatures(kmeans, desc_list, count, no_clusters=no_clusters)\n",
    "    test_features = scale.transform(test_features)\n",
    "    pred=LRG.predict(test_features)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = test(testImgPaths,kmeans,LRG,scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9722222222222222"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(pred, testLabels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
